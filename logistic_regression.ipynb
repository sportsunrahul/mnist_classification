{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sport\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(train_num_images,test_num_images,image_size,train_image_file,train_label_file,test_image_file,test_label_file):\n",
    "    \n",
    "    train_image_file = gzip.open(train_image_file,'r')\n",
    "    train_label_file = gzip.open(train_label_file,'r')\n",
    "    test_image_file = gzip.open(test_image_file,'r')\n",
    "    test_label_file = gzip.open(test_label_file,'r')\n",
    "\n",
    "    # Read Training Images\n",
    "    train_image_file = gzip.open('train-images-idx3-ubyte.gz','r')\n",
    "    train_image_file.read(16)\n",
    "    buf = train_image_file.read(image_size * image_size * train_num_images)\n",
    "    train_images = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    train_images = train_images.reshape(train_num_images, image_size, image_size, 1)\n",
    "\n",
    "    # Read Training Labels\n",
    "    train_label_file.read(8)\n",
    "    buf = train_label_file.read(train_num_images)\n",
    "    train_labels = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "\n",
    "    # Read Testing Images\n",
    "    test_image_file.read(16)\n",
    "    buf = test_image_file.read(image_size * image_size * test_num_images)\n",
    "    test_images = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    test_images = test_images.reshape(test_num_images, image_size, image_size, 1)\n",
    "\n",
    "    # Read Testing Labels\n",
    "    test_label_file.read(8)\n",
    "    buf = test_label_file.read(test_num_images)\n",
    "    test_labels = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    \n",
    "    return train_images,train_labels,test_images,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(x_train,y_train,x_test,y_test):\n",
    "    iter = [10,20,30,40,50,75,100,150,200]\n",
    "    opt_iter = 1\n",
    "    max_score = 0\n",
    "    for i in iter:\n",
    "        logisticRegr = LogisticRegression(solver = 'lbfgs', max_iter = i, multi_class = 'multinomial', n_jobs=1, tol=0.0001, verbose=0)\n",
    "        logisticRegr.fit(x_train, y_train)\n",
    "        train_score = logisticRegr.score(x_train, y_train)\n",
    "        val_score = logisticRegr.score(x_test, y_test)\n",
    "        print(\"Maximum Iterations:{}, Train Accuracy:{:2.4}, Validation Accuracy:{:2.4}\".format(i,100*train_score,100*val_score))\n",
    "        if(val_score> max_score):\n",
    "            max_score = val_score\n",
    "            opt_iter = i\n",
    "    print(\"Optimum:\", opt_iter, 100*max_score)\n",
    "    \n",
    "    return opt_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_num_images = 60000\n",
    "    test_num_images = 10000\n",
    "    image_size = 28\n",
    "    \n",
    "    train_image_file = 'train-images-idx3-ubyte.gz'\n",
    "    train_label_file = 'train-labels-idx1-ubyte.gz'\n",
    "    test_image_file = 't10k-images-idx3-ubyte.gz'\n",
    "    test_label_file = 't10k-labels-idx1-ubyte.gz'\n",
    "    train_images,train_labels,test_images,test_labels = read_data(train_num_images,test_num_images,image_size,\\\n",
    "                                                                  train_image_file,train_label_file,test_image_file,\\\n",
    "                                                                  test_label_file)\n",
    "    # Reshaping Images for training and testing\n",
    "    train_images = train_images.reshape(train_num_images,784)\n",
    "    test_images = test_images.reshape(test_num_images,784)\n",
    "    \n",
    "    # Splitting training data into trainig and validation data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.25, random_state=0)\n",
    "\n",
    "    # Finding optimum number of iterations\n",
    "    opt_iter = hyperparameter_tuning(x_train,y_train,x_test,y_test)\n",
    "    \n",
    "    # Training on the whole training dataset\n",
    "    logisticRegr = LogisticRegression(solver = 'lbfgs', max_iter = opt_iter, multi_class = 'multinomial', n_jobs=1, tol=0.0001, verbose=0)\n",
    "    logisticRegr.fit(train_images, train_labels)\n",
    "    train_score = logisticRegr.score(train_images, train_labels)\n",
    "    print(\"Train Accuracy:{:2.4}\".format(100*train_score))\n",
    "\n",
    "    predictions = logisticRegr.predict(test_images)\n",
    "    test_score = logisticRegr.score(test_images, test_labels)\n",
    "    print(\"Test Accuracy:{:2.4}\".format(100*test_score))\n",
    "    \n",
    "    \n",
    "    # Dumping testing results into csv file\n",
    "    results = to_categorical(predictions,num_classes = 10)\n",
    "    np.savetxt(\"lr.csv\", results, fmt = '%4d', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(45000, 784)\n",
      "(15000, 784)\n",
      "Maximum Iterations:10, Train Accuracy:88.69, Validation Accuracy:88.66\n",
      "Maximum Iterations:20, Train Accuracy:91.15, Validation Accuracy:90.87\n",
      "Maximum Iterations:30, Train Accuracy:92.13, Validation Accuracy:91.69\n",
      "Maximum Iterations:40, Train Accuracy:92.52, Validation Accuracy:92.11\n",
      "Maximum Iterations:50, Train Accuracy:92.74, Validation Accuracy:91.97\n",
      "Maximum Iterations:75, Train Accuracy:93.23, Validation Accuracy:92.12\n",
      "Maximum Iterations:100, Train Accuracy:93.52, Validation Accuracy:91.95\n",
      "Maximum Iterations:150, Train Accuracy:93.79, Validation Accuracy:91.83\n",
      "Maximum Iterations:200, Train Accuracy:94.02, Validation Accuracy:91.69\n",
      "Optimum: 75 92.12\n",
      "Train Accuracy:93.18\n",
      "Test Accuracy:92.38\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
